# üç∑ Give Me The Wine Price - Application de Pr√©diction du Prix du Vin

Ce d√©p√¥t (`corbenol/GiveMeTheWinePrice`) contient l'int√©gralit√© de la cha√Æne MLOps pour l'entra√Ænement, la validation, le monitoring et le d√©ploiement d'un mod√®le de r√©gression permettant de pr√©dire un prix pour une bouteille de vin.

L'application d'inf√©rence est une API **FastAPI** qui utilise **MLflow** pour charger le mod√®le de production et **Neon (PostgreSQL)** pour la journalisation des requ√™tes (Inference Logging).

GiveMeTheWinePrice est une application de pr√©diction du **prix du vin**. L‚Äôid√©e est de fournir, √† partir de caract√©ristiques d‚Äôun vin (mill√©sime, descrption oenologique, pays, r√©gions), une estimation de son prix de march√©.  

Elle peut servir d‚Äôoutil d‚Äôaide √† la d√©cision pour des collectionneurs, des revendeurs ou toute personne int√©ress√©e par l‚Äô√©valuation de bouteilles de vin.

## üöÄ Architecture MLOps et Composants

L'architecture est construite sur une s√©paration claire des environnements :

| **Composant** | **R√¥le** | **Technologie** | **R√©pertoire** | **Environnement** | 
| :--- | :--- | :--- | :--- | :--- | 
| **Tracking Server** | Serveur central pour le suivi des exp√©riences et la gestion des mod√®les. | MLflow / Docker | `tracker_aws/` | **EC2 AWS** | 
| **Entra√Ænement** | Ex√©cution de l'entra√Ænement, du logging et de l'enregistrement du mod√®le. | Docker / Python | `model/` | **EC2 via SSH/GitHub Actions** | 
| **Monitoring** | Surveillance de la d√©rive (drift) du mod√®le en comparant la performance en production √† la performance de r√©f√©rence. |  Python | `drift/` | **GitHub Actions** | 
| **API Web (Inf√©rence)** | Pr√©diction et journalisation des donn√©es dans Neon DB. | FastAPI / MLflow | `api/` | **Hugging Face Spaces** | 

## üõ†Ô∏è Infrastructure et Fichiers Cl√©s

| **Fichier/R√©pertoire** | **Description** | **Utilis√© par Workflow** | 
| :--- | :--- | :--- | 
| `analyse/eda.ipynb` | Notebook d'analyse exploratoire des donn√©es (EDA) et de nettoyage. | (Manuel) | 
| `model/train.py` | Script principal d'entra√Ænement et d'enregistrement du mod√®le dans MLflow. | `mlflow-train.yml` | 
| `model/MLproject` | D√©finition des entr√©es et commandes pour une ex√©cution reproductible du mod√®le (MLflow Project). | (MLflow) | 
| `model/tests/` | Contient les tests unitaires pour la logique du mod√®le (chargement, signature, pr√©dictions). | `mlflow-test.yml` | 
| `api/app.py` | Code de l'API FastAPI, incluant la connexion √† Neon DB et le chargement du mod√®le de production. | `api-deploy.yml` | 
| `api/tests/` | Contient les tests d'int√©gration de l'API (v√©rification sant√©, requ√™tes valides/invalides). | `api-deploy.yml` | 
| `drift/drift_monitor.py` | Script de monitoring qui compare la RMSE de production aux m√©triques de r√©f√©rence MLflow. | `drift_monitoring.yaml` | 
| `.github/workflows/` | Contient les quatre workflows CI/CD. | Tous | 

## üìÅ Arborescence du Projet

Voici l'organisation principale du d√©p√¥t :  

.
‚îú‚îÄ‚îÄ .github/
‚îÇ ‚îî‚îÄ‚îÄ workflows/
‚îÇ ‚îú‚îÄ‚îÄ api-deploy.yml # D√©ploiement de l'API sur Hugging Face
‚îÇ ‚îú‚îÄ‚îÄ drift_monitoring.yaml # Surveillance de la d√©rive (drift)
‚îÇ ‚îú‚îÄ‚îÄ mlflow-test.yml # Tests unitaires et promotion du mod√®le
‚îÇ ‚îî‚îÄ‚îÄ mlflow-train.yml # Entra√Ænement sur EC2 via SSH
‚îú‚îÄ‚îÄ analyse/
‚îÇ ‚îî‚îÄ‚îÄ eda.ipynb # Analyse exploratoire des donn√©es
‚îú‚îÄ‚îÄ api/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile # Image Docker pour le d√©ploiement de l'API
‚îÇ ‚îú‚îÄ‚îÄ app.py # Application principale FastAPI (Inf√©rence)
‚îÇ ‚îú‚îÄ‚îÄ app.sav # Mod√®le s√©rialis√© pour le dev local
‚îÇ ‚îú‚îÄ‚îÄ requirements-api.txt # D√©pendances Python pour l'API
‚îÇ ‚îú‚îÄ‚îÄ test_url.sh # Script de test de l'URL de l'API
‚îÇ ‚îî‚îÄ‚îÄ tests/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.test # Image pour les tests d'int√©gration API
‚îÇ ‚îú‚îÄ‚îÄ conftest.py # Configuration Pytest
‚îÇ ‚îú‚îÄ‚îÄ requirements-test.txt # D√©pendances pour les tests
‚îÇ ‚îú‚îÄ‚îÄ test_health.py # Test de l'endpoint /health
‚îÇ ‚îú‚îÄ‚îÄ test_prediction_invalid.py # Test des requ√™tes invalides
‚îÇ ‚îú‚îÄ‚îÄ test_prediction_valid.py # Test des requ√™tes valides
‚îÇ ‚îî‚îÄ‚îÄ wait_for_api.py # Attente du d√©marrage de l'API
‚îú‚îÄ‚îÄ drift/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.drift # Image Docker monitoring
‚îÇ ‚îú‚îÄ‚îÄ drift_monitor.py # Script Evidently AI
‚îÇ ‚îî‚îÄ‚îÄ requirements-drift.txt # D√©pendances monitoring
‚îú‚îÄ‚îÄ model/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.train # Image Docker pour l'entra√Ænement
‚îÇ ‚îú‚îÄ‚îÄ MLproject # Config MLflow
‚îÇ ‚îú‚îÄ‚îÄ requirements-train.txt # D√©pendances pour l'entra√Ænement
‚îÇ ‚îú‚îÄ‚îÄ secret.sh # Secrets (local/EC2)
‚îÇ ‚îú‚îÄ‚îÄ tests/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.test # Image tests du mod√®le
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ conftest.py # Config Pytest
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ requirements-test.txt # D√©pendances tests
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test_model_load.py # Test de chargement du mod√®le
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test_predictions.py # Test pr√©dictions simples
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ test_signature.py # Test signature MLflow
‚îÇ ‚îî‚îÄ‚îÄ train.py # Script d'entra√Ænement MLflow
‚îú‚îÄ‚îÄ tracker_aws/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile # Dockerfile MLflow Server
‚îÇ ‚îú‚îÄ‚îÄ build.sh # Build de l'image
‚îÇ ‚îú‚îÄ‚îÄ commande_ssh_EC2.sh # Exemples de commandes SSH
‚îÇ ‚îú‚îÄ‚îÄ mlflow.env # Variables d'environnement
‚îÇ ‚îú‚îÄ‚îÄ requirements.txt # D√©pendances MLflow Server
‚îÇ ‚îî‚îÄ‚îÄ run_docker.sh # Lancement du conteneur MLflow
‚îî‚îÄ‚îÄ README.md # Documentation du projet

## ‚öôÔ∏è Workflows MLOps avec GitHub Actions

Les pipelines CI/CD sont g√©r√©s par les tags Git pour contr√¥ler pr√©cis√©ment les √©tapes d'entra√Ænement, de test, de d√©ploiement et de monitoring.

| **Fichier Workflow** | **D√©clencheur (Tag ou √âv√©nement)** | **√âtapes Cl√©s** | 
| :--- | :--- | :--- | 
| **`mlflow-train.yml`** | Tag `train-*` (ex: `train-v1.2`) | Configure SSH, synchronise le code avec EC2, construit l'image Docker (`model/Dockerfile.train`) sur EC2, et ex√©cute `model/train.py` via SSH. | 
| **`mlflow-test.yml`** | Succ√®s de `mlflow-train.yml` | Construit l'image de test, ex√©cute `pytest`, et si les tests r√©ussissent, **proscrit l'alias MLflow de la version test√©e √† `production`**. | 
| **`api-deploy.yml`** | Tag `deploy-*` (ex: `deploy-20251130`) | Ex√©cute des tests d'int√©gration (via une image Docker de test), puis utilise la CLI `huggingface_hub` pour mettre √† jour le Space `corbenol/wine-price-predictor`. | 
| **`drift_monitoring.yaml`** | Tag `drift-*` (ou calendrier) | Construit l'image Docker de d√©rive, ex√©cute `drift/drift_monitor.py` pour √©valuer la performance du mod√®le en production et √©choue si la d√©rive d√©passe le seuil d√©fini. | 

## ‚òÅÔ∏è D√©ploiement et Configuration

### 1. Configuration des Secrets GitHub (Environnement)

Tous les workflows n√©cessitent la configuration des secrets suivants dans les param√®tres de votre d√©p√¥t GitHub (`Settings > Secrets > Actions`):

| **Secret** | **Utilis√© par** | **R√¥le** | 
| :--- | :--- | :--- | 
| `EC2_SSH_PRIVATE_KEY` | `mlflow-train.yml` | Cl√© SSH priv√©e pour la connexion et l'ex√©cution de Docker sur le serveur EC2. | 
| `EC2_HOST` | `mlflow-train.yml` | Adresse IP ou DNS du serveur d'entra√Ænement EC2. | 
| `BACKEND_STORE_URI` | Tous les workflows | URI du serveur MLflow (ex: `http://ec2-xx-xx-xx-xx:5000/`). | 
| `AWS_ACCESS_KEY_ID` | Tous les workflows | Cl√© d'acc√®s S3 (artefacts MLflow et donn√©es de drift). | 
| `AWS_SECRET_ACCESS_KEY` | Tous les workflows | Cl√© secr√®te d'acc√®s S3. | 
| `NEON_TEST` | `api-deploy.yml` | URI de la base de donn√©es Neon pour les tests d'int√©gration de l'API. | 
| `HF_TOKEN` | `api-deploy.yml` | Jeton d'acc√®s Hugging Face pour la mise √† jour du Space. | 
| `ARTIFACT_DATA` | `mlflow-train.yml`, `drift_monitoring.yaml` | Chemin S3 vers les donn√©es brutes (ex: `s3://mon-bucket-wine-data/`). | 

### 2. D√©marrage du Serveur de Suivi MLflow (EC2)

Le serveur de suivi est d√©ploy√© dans un conteneur Docker sur EC2. Pour le d√©marrer :

1. Connectez-vous √† votre instance EC2.

2. Dans le r√©pertoire `tracker_aws/`, ex√©cutez le script `build.sh` pour cr√©er l'image Docker.

3. Ex√©cutez `run_docker.sh` pour lancer le conteneur, en configurant les variables d'environnement n√©cessaires (`AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, etc.).

### 3. D√©ploiement de l'API (Hugging Face)

Le d√©ploiement est automatique apr√®s un tag `deploy-*` et l'ex√©cution r√©ussie des tests d'int√©gration dans `api-deploy.yml`. Ce workflow copie les fichiers essentiels (`api/app.py`, `api/requirements-api.txt`, `api/Dockerfile`) et les pousse vers le Space Hugging Face cible (`corbenol/wine-price-predictor`).

## üîé Comment Utiliser et Tester l'API (Inf√©rence)

L'API est accessible sur un service Space Hugging Face (ex: `https://corbenol-wine-price-predictor.hf.space`).

### Endpoint de Sant√© (`/health`)

V√©rifie l'√©tat du service et confirme la version du mod√®le charg√© √† partir de l'alias `production` de MLflow.

### Endpoint de Pr√©diction (`/predict`)

**M√©thode:** `POST`

**Sch√©ma de la Requ√™te (JSON):**

{ "country": "france", "description": "art and snappy, the flavors of lime flesh and rind dominate.", "province": "bordeaux", "millesime": "2018" }


**Exemple de Commande cURL  :**

curl -X POST 'https://corbenol-wine-price-predictor.hf.space/predict'

-H 'Content-Type: application/json'

-d '{ "country": "france", "description": "Tart and snappy, the flavors of lime flesh and rind dominate", "province": "Alsace", "millesime": "2022" }'